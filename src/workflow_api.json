{
  "3": {
    "inputs": {
      "seed": 918713283459505,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "lcm",
      "scheduler": "simple",
      "denoise": 1,
      "model": ["54", 0],
      "positive": ["59", 0],
      "negative": ["59", 1],
      "latent_image": ["59", 2]
    },
    "class_type": "KSampler",
    "_meta": {"title": "KSampler"}
  },
  "6": {
    "inputs": {
      "text": "",
      "clip": ["58", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP Text Encode (Positive Prompt)"}
  },
  "7": {
    "inputs": {
      "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走, blurry, mouth moving, talking, teeth visible, strong blush, zoom out, zoom in, slow motion",
      "clip": ["58", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {"title": "CLIP Text Encode (Negative Prompt)"}
  },
  "38": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {"title": "Load CLIP"}
  },
  "39": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {"title": "Load VAE"}
  },
  "49": {
    "inputs": {
      "clip_name": "clip_vision_h.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {"title": "Load CLIP Vision"}
  },
  "51": {
    "inputs": {
      "crop": "none",
      "clip_vision": ["49", 0],
      "image": ["52", 0]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {"title": "CLIP Vision Encode"}
  },
  "52": {
    "inputs": {
      "image": "input.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {"title": "Load Image (Start Frame)"}
  },
  "54": {
    "inputs": {
      "shift": 8.0,
      "model": ["58", 0]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {"title": "ModelSamplingSD3"}
  },
  "55": {
    "inputs": {
      "unet_name": "wan2.1-i2v-14b-480p-Q3_K_S.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {"title": "Unet Loader (GGUF)"}
  },
  "58": {
    "inputs": {
      "lora_name": "WAN2.1/birdmanstyleanimationwanlora.safetensors",
      "strength_model": 1.0,
      "strength_clip": 1.0,
      "model": ["58_2", 0],
      "clip": ["38", 0]
    },
    "class_type": "LoraLoader",
    "_meta": {"title": "Load LoRA (Style)"}
  },
  "58_2": {
    "inputs": {
      "lora_name": "Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32.safetensors",
      "strength_model": 1.0,
      "strength_clip": 1.0,
      "model": ["55", 0],
      "clip": ["38", 0]
    },
    "class_type": "LoraLoader",
    "_meta": {"title": "Load LoRA (Speed/Distill)"}
  },
  "59": {
    "inputs": {
      "width": 480,
      "height": 832,
      "length": 21,
      "positive": ["6", 0],
      "negative": ["7", 0],
      "vae": ["39", 0],
      "start_image": ["93", 0],
      "end_image": ["103", 0],
      "clip_vision_output": ["51", 0]
    },
    "class_type": "WanImageToVideo_F2",
    "_meta": {"title": "Wan Image To Video (Start/End Frames)"}
  },
  "61": {
    "inputs": {
      "tile_size": 192,
      "overlap": 64,
      "temporal_size": 28,
      "temporal_overlap": 8,
      "samples": ["3", 0],
      "vae": ["39", 0]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {"title": "VAE Decode Tiled"}
  },
  "68": {
    "inputs": {
      "images": ["61", 0]
    },
    "class_type": "ImageListToImageBatch",
    "_meta": {"title": "Image List to Batch"}
  },
  "69": {
    "inputs": {
      "batch_index": 0,
      "length": 20,
      "image": ["68", 0]
    },
    "class_type": "ImageFromBatch",
    "_meta": {"title": "Remove Last Frame"}
  },
  "70": {
    "inputs": {
      "images": ["69", 0]
    },
    "class_type": "ImageListToImageBatch",
    "_meta": {"title": "Final Image Batch"}
  },
  "93": {
    "inputs": {
      "width": 480,
      "height": 832,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "if bigger area",
      "multiple_of": 0,
      "image": ["52", 0]
    },
    "class_type": "ImageResize+",
    "_meta": {"title": "Resize Start Image"}
  },
  "102": {
    "inputs": {
      "image": "input.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {"title": "Load Image (End Frame)"}
  },
  "103": {
    "inputs": {
      "width": 480,
      "height": 832,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "if bigger area",
      "multiple_of": 0,
      "image": ["102", 0]
    },
    "class_type": "ImageResize+",
    "_meta": {"title": "Resize End Image"}
  },
  "126": {
    "inputs": {
      "filename_prefix": "seamless_loop",
      "fps": 12,
      "lossless": true,
      "quality": 80,
      "method": "default",
      "images": ["70", 0]
    },
    "class_type": "SaveAnimatedWEBP",
    "_meta": {"title": "Save Animated WEBP"}
  }
}
